{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sample4geo.dataset.cvusa import CVUSADatasetEval\n",
    "from sample4geo.transforms import get_transforms_val\n",
    "from sample4geo.evaluate.cvusa_and_cvact import evaluate\n",
    "from sample4geo.model import TimmModel\n",
    "from inference import Configuration"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:14.897252Z",
     "start_time": "2024-01-12T17:34:11.871324Z"
    }
   },
   "id": "7a3ed915b6a1d013"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = Configuration()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:14.902234Z",
     "start_time": "2024-01-12T17:34:14.897866Z"
    }
   },
   "id": "b2abe0abe200d452"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:14.902676Z",
     "start_time": "2024-01-12T17:34:14.900310Z"
    }
   },
   "id": "df4133f27110016b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': (3, 384, 384), 'interpolation': 'bicubic', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'crop_pct': 1.0, 'crop_mode': 'squash'}\n",
      "Start from: pretrained/cvusa/convnext_base.fb_in22k_ft_in1k_384/weights_e40_98.6830.pth\n",
      "GPUs available: 0\n",
      "\n",
      "Image Size Sat: (384, 384)\n",
      "Image Size Ground: (140, 768)\n",
      "Mean: (0.485, 0.456, 0.406)\n",
      "Std:  (0.229, 0.224, 0.225)\n"
     ]
    }
   ],
   "source": [
    "model = TimmModel(config.model,\n",
    "                      pretrained=True,\n",
    "                      img_size=config.img_size)\n",
    "data_config = model.get_config()\n",
    "print(data_config)\n",
    "mean = data_config[\"mean\"]\n",
    "std = data_config[\"std\"]\n",
    "img_size = config.img_size\n",
    "\n",
    "image_size_sat = (img_size, img_size)\n",
    "\n",
    "new_width = config.img_size * 2    \n",
    "new_hight = round((224 / 1232) * new_width)\n",
    "img_size_ground = (new_hight, new_width)\n",
    " \n",
    "# load pretrained Checkpoint    \n",
    "if config.checkpoint_start is not None:  \n",
    "    print(\"Start from:\", config.checkpoint_start)\n",
    "    model_state_dict = torch.load(config.checkpoint_start,map_location=torch.device('cpu'))  \n",
    "    model.load_state_dict(model_state_dict, strict=False)     \n",
    "\n",
    "# Data parallel\n",
    "print(\"GPUs available:\", torch.cuda.device_count())  \n",
    "if torch.cuda.device_count() > 1 and len(config.gpu_ids) > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=config.gpu_ids)\n",
    "        \n",
    "# Model to device   \n",
    "model = model.to(config.device)\n",
    "\n",
    "print(\"\\nImage Size Sat:\", image_size_sat)\n",
    "print(\"Image Size Ground:\", img_size_ground)\n",
    "print(\"Mean: {}\".format(mean))\n",
    "print(\"Std:  {}\\n\".format(std)) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:17.135918Z",
     "start_time": "2024-01-12T17:34:14.903049Z"
    }
   },
   "id": "799c0f61f01f100a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DataSetEval(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_folder,\n",
    "                 img_type,\n",
    "                 transforms=None,\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.data_folder = data_folder\n",
    "        self.img_type = img_type # 'ground' or 'aerial'\n",
    "        label = range(19) if img_type == 'aerial' else [0]\n",
    "        self.label = np.array(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = f'{index}.png'\n",
    "        if self.img_type == 'aerial':\n",
    "            file_name = 'satellite_res' + file_name\n",
    "        img = cv2.imread(f'{self.data_folder}/{self.img_type}/{file_name}')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = torch.tensor(self.label[index], dtype=torch.long)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return 19 if self.img_type == 'aerial' else 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:17.141917Z",
     "start_time": "2024-01-12T17:34:17.135590Z"
    }
   },
   "id": "eff1eeee8681374d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 1\n"
     ]
    }
   ],
   "source": [
    "aerial_dataset = DataSetEval(config.data_folder, 'aerial')\n",
    "aerial_dataloader = DataLoader(aerial_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
    "ground_dataset = DataSetEval(config.data_folder, 'ground')\n",
    "ground_dataloader = DataLoader(ground_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
    "\n",
    "print(len(aerial_dataset), len(ground_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:17.142128Z",
     "start_time": "2024-01-12T17:34:17.139153Z"
    }
   },
   "id": "ced80c28ae74a864"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extract Features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'DataSetEval' on <module '__main__' (built-in)>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'DataSetEval' on <module '__main__' (built-in)>\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'DataSetEval' on <module '__main__' (built-in)>\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'DataSetEval' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 30461, 30462) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1132\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    112\u001B[0m timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/connection.py:440\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 440\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/multiprocessing/connection.py:947\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    946\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 947\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    948\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 30461) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreference_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maerial_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mground_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m               \u001B[49m\u001B[43mcleanup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/llm/geolocation/tools/Sample4Geo/sample4geo/evaluate/cvusa_and_cvact.py:20\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(config, model, reference_dataloader, query_dataloader, ranks, step_size, cleanup)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(config,\n\u001B[1;32m     11\u001B[0m              model,\n\u001B[1;32m     12\u001B[0m              reference_dataloader,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m              step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m,\n\u001B[1;32m     16\u001B[0m              cleanup\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mExtract Features:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m     reference_features, reference_labels \u001B[38;5;241m=\u001B[39m \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreference_dataloader\u001B[49m\u001B[43m)\u001B[49m \n\u001B[1;32m     21\u001B[0m     query_features, query_labels \u001B[38;5;241m=\u001B[39m predict(config, model, query_dataloader)\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompute Scores:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/dev/llm/geolocation/tools/Sample4Geo/sample4geo/trainer.py:130\u001B[0m, in \u001B[0;36mpredict\u001B[0;34m(train_config, model, dataloader)\u001B[0m\n\u001B[1;32m    127\u001B[0m ids_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 130\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbar\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mids_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mautocast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/tqdm/std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1185\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/geoloc/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1145\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1144\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1145\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 30461, 30462) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "res = evaluate(config=config, model=model, reference_dataloader=aerial_dataloader, query_dataloader=ground_dataloader,\n",
    "               cleanup=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:19.077337Z",
     "start_time": "2024-01-12T17:34:17.142697Z"
    }
   },
   "id": "3a6c5f40aae02835"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T17:34:19.081009Z",
     "start_time": "2024-01-12T17:34:19.078016Z"
    }
   },
   "id": "1f8ed0b264cb8bc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
