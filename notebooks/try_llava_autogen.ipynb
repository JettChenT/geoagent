{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:19:15.879112Z",
     "start_time": "2023-12-23T06:19:15.867352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "LLAVA_MODE = \"remote\" # Either \"local\" or \"remote\"\n",
    "assert LLAVA_MODE in [\"local\", \"remote\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:19:16.507388Z",
     "start_time": "2023-12-23T06:19:16.500635Z"
    }
   },
   "id": "a85bdc4953b59fb"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, Agent, UserProxyAgent, ConversableAgent\n",
    "from termcolor import colored\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:19:23.783462Z",
     "start_time": "2023-12-23T06:19:21.774407Z"
    }
   },
   "id": "41ca385ac8a99b09"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "if LLAVA_MODE == \"remote\":\n",
    "    import replicate\n",
    "    \n",
    "    llava_config_list = [\n",
    "        {\n",
    "            \"model\": \"whatever, will be ignored for remote\", # The model name doesn't matter here right now.\n",
    "            \"api_key\": \"None\", # Note that you have to setup the API key with os.environ[\"REPLICATE_API_TOKEN\"] \n",
    "            \"base_url\": \"yorickvp/llava-13b:2facb4a474a0462c15041b78b1ad70952ea46b5ec6ad29583c0b29dbd4249591\",\n",
    "        }\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:03:27.046721Z",
     "start_time": "2023-12-23T06:03:27.039125Z"
    }
   },
   "id": "ff3a1f46772ae254"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.llava_agent import llava_call"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:03:27.666530Z",
     "start_time": "2023-12-23T06:03:27.663526Z"
    }
   },
   "id": "7e8133a4d2c494cb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* AutoGen framework is a tool for creating and managing conversational agents.\n",
      "* It allows for the creation of conversational agents using a visual interface, where users can design the agent's dialogue flow and responses.\n",
      "* The framework supports multiple conversational agents, enabling them to interact with each other and share information.\n",
      "* The visual interface provides a clear representation of the agent's dialogue flow, making it easier to understand and modify the conversational agent's behavior.\n",
      "* The framework allows for the integration of different conversational agents, enabling them to work together and provide more comprehensive and personalized interactions with users.\n",
      "* The visual representation of the agent's dialogue flow and the ability to integrate multiple agents make the AutoGen framework a powerful tool for creating and managing conversational agents.\n"
     ]
    }
   ],
   "source": [
    "rst = llava_call(\"Describe this AutoGen framework <img https://raw.githubusercontent.com/microsoft/autogen/main/website/static/img/autogen_agentchat.png> with bullet points.\",\n",
    "          llm_config={\n",
    "              \"config_list\": llava_config_list,\n",
    "              \"temperature\": 0\n",
    "          })\n",
    "\n",
    "print(rst)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:03:44.920887Z",
     "start_time": "2023-12-23T06:03:30.838640Z"
    }
   },
   "id": "7afeee10741f21b1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOG_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "CFIG_LIST = [\n",
    "    {\n",
    "        \"model\": \"gemini-pro-vision\",\n",
    "        \"api_key\": GOOG_API_KEY,\n",
    "        \"api_type\": \"google\"\n",
    "    }\n",
    "]\n",
    "\n",
    "os.environ[\"CFIG_LIST\"] = json.dumps(CFIG_LIST)\n",
    "\n",
    "gemini_vision_config = autogen.config_list_from_json(\n",
    "    \"CFIG_LIST\",\n",
    "    filter_dict={\"model\": [\"gemini-pro-vision\"]}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:19:29.733791Z",
     "start_time": "2023-12-23T06:19:29.731664Z"
    }
   },
   "id": "bee5178bb471c7ae"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'model': 'gemini-pro-vision',\n  'api_key': 'AIzaSyCMMV4BEqL41M5ejmGOZgnDMgu-rO3w9w0',\n  'api_type': 'google'}]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_vision_config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:19:30.546582Z",
     "start_time": "2023-12-23T06:19:30.540893Z"
    }
   },
   "id": "b58d7cbd1fb57ca0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33muser_proxy\u001B[0m (to Gemini Vision):\n",
      "\n",
      "\n",
      "\n",
      "The you will receive a picture of a location in the world, note the important features in it.\n",
      "Write open streetmap queires to find these locations.\n",
      "In your queries, make use of OSM's proximity features, and use regular expressions over exact string matches, and always use them\n",
      "when you're not exactly sure of the specific wordings of signs etc.\n",
      "Finally, output a single query to find the image's likely location, including the headers and bounding boxes, etc.\n",
      "If you are able to guess the general region of the image. Please include that in the OSM query.\n",
      "\n",
      "A good example of a query would be:\n",
      "\n",
      "```\n",
      "area[\"name\"~\".*Washington.*\"];\n",
      "way[\"name\"~\"Monroe.*St.*NW\"](area) -> .mainway;\n",
      "\n",
      "(\n",
      "  nwr(around.mainway:500)[\"name\"~\"Korean.*Steak.*House\"];\n",
      "\n",
      "  // Find nearby businesses with CA branding\n",
      "  nwr(around.mainway:500)[\"name\"~\"^CA.*\"];\n",
      "  \n",
      "  // Look for a sign with the words \"Do not block\"\n",
      "  node(around.mainway:500)[\"traffic_sign\"~\"Do not block\"];\n",
      ");\n",
      "\n",
      "out center;\n",
      "```\n",
      "\n",
      "Where is this image located?\n",
      "<image>\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001B[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model gemini-pro-vision not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "\u001B[33mGemini Vision\u001B[0m (to user_proxy):\n",
      "\n",
      " This image is located in New York City. The street signs say \"East 96th Street\" and \"2nd Avenue\". There are also signs for \"Hammarskjold Plaza\" and \"John Finley Walk\".\n",
      "\n",
      "```\n",
      "area[\"name\"~\"New York City\"];\n",
      "way[\"name\"~\"2nd Ave.*\"](area) -> .mainway;\n",
      "way[\"name\"~\"E 96th St.*\"](area) -> .crossway;\n",
      "(\n",
      "  nwr(around.crossway:500)[\"name\"~\"Hammarskjold.*Plaza\"];\n",
      "  nwr(around.crossway:500)[\"name\"~\"John Finley.*Walk\"];\n",
      ");\n",
      "out center;\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.llava_agent import LLaVAAgent\n",
    "from prompting import INITIAL_PROMPT\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "\n",
    "image_agent = MultimodalConversableAgent(\"Gemini Vision\", \n",
    "                           llm_config={\"config_list\": gemini_vision_config, \"seed\": 42}, \n",
    "                           max_consecutive_auto_reply=1,\n",
    "                           code_execution_config=False\n",
    "                        )\n",
    "\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                            human_input_mode=\"NEVER\",\n",
    "                            max_consecutive_auto_reply=0)\n",
    "\n",
    "# Ask the question with an image\n",
    "user_proxy.initiate_chat(image_agent, message = f\"\"\"\n",
    "{INITIAL_PROMPT}\n",
    "Where is this image located?\n",
    "<img https://ik.imagekit.io/sfwall/NY5_J2A4Si6Z6.png?updatedAt=1702987667392>\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-23T06:22:49.156569Z",
     "start_time": "2023-12-23T06:22:23.933707Z"
    }
   },
   "id": "34ecc8c58b77bd9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9099524ccab6c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
